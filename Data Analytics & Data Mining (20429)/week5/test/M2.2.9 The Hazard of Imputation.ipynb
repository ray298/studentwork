{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hxZFTlEg_JJY"},"source":["# **The Hazards of Imputation**\n"," I have already mentioned the pitfall of potentially biasing your results when you use the wrong technique or make unreasonable assumptions. It is really worth keeping focused on examining your assumptions. I continually tell students that statistics and machine learning are about trying to prove a point. Think of it like a court of law, you continually need evidence to prove your point. So when you handle missing data make sure you examine your assumptions. Write them down and then complete an analysis for each one. So for example if you do decide the variable with the missing data is a MCAR then prove that the estimate that you intend to use for the missing values is appropriate. So look at the spread of the data and see if it suits a constant, mean, median or mode. I have asked students during their MSc viva's what technique they used. 9/10 say they imputed them with the mean, and usually has no evidence to support it. **This is a huge No-No.**\n","\n","The final point I will make is, if you decide to impute then run repeated analysis of your model with differing samples from your data. If you do this the samples with imputed missing values should not stick out. So if you were making a prediction model do the test results change when you rely on missing data. You will come across this in K-folds for neaural networks in the future, and it is also known as bootstrapping in statistics.\n","\n","We will now move on to a small quiz. Best of luck.\n","\n","\n","\n","\n","\n","\n"]}]}