{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M4.4.2 Clustering .ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOFSYRd5tQz5OpL9uJhw6QU"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0ujTZGuiZk6u","colab_type":"text"},"source":["#**What is Clustering?**\n","\n","\n","\n","Clustering is the process of finding groups of objects such  that the objects in a group\n","will be similar (or related) to one another and  different from\n","(or unrelated to) the objects in other groups, Figure 1.\n","![](https://www.computing.dcu.ie/~amccarren/mcm_images/cluster_analysis.png)\n","\n","Figure 1 (Chiara Renso,KDD-LAB,ISTI- CNR, Pisa, Italy)\n","\n"," Clustering falls into a category of machine learning known as unsupervised learner. The idea behind it is to apply an algorithm (for which there are many) which will use a similarity or distance function, for example, to seperate the data you have into groups. Unlike Principal Component Analysis (PCA) which combines columns/features, cluster analysis generally groups by row. So you are really trying to combine groups of people or objects which would have a multitude of variables/features. For example you may have done a survey about the reading habits of people. In this survey you have asked people if they worked in various sectors, had a certain level of education, where they lived or what their parents read. Now cluster analysis will attempt to group all the people based on their answers to the 4 questions. \n","\n","Clustering is really useful when attempting to determine intrinsic grouping among unlabeled data. For example, we may want to subdivide the market into segmented components as follows:\n","\n","Market Segmentation:\n","> * Goal: subdivide a market into distinct subsets of \n","customers where any  subset may  conceivably be \n","selected as a market target to be reached with a \n","distinct marketing mix.\n","> * Approach: \n",">> * Collect different attributes of customers based on their geographical and  lifestyle related information.\n",">> * Find clusters of similar customers.\n",">> * Measure the clustering quality by observing buying \n","patterns of customers in same cluster vs. those from \n","different clusters.\n","\n","Or alternatively we may want to cluster documents:\n","\n","Document Clustering:\n","> *     Goal: To find groups of documents that are similar to each  other based on the important terms appearing in them, Figure 2.\n","> *     Approach: To identify frequently occurring terms in \n","each  document. Form a similarity measure based on \n","the frequencies of different terms. Use it to cluster.\n","> *     Gain: Information Retrieval can utilize the clusters \n","to relate a new document or search term to clustered \n","documents.\n","\n","\n","Clustering Points: 3204 Articles of Los Angeles Times\n","Similarity Measure: How many words  are common in\n","these documents after some word filtering.\n","\n","![](https://www.computing.dcu.ie/~amccarren/mcm_images/cluster_analysis_2.png)\n","\n","\n","As I said previously there are many cluster algorithms, and they can categorized as follows:\n","\n","1. Density-Based Methods : These methods consider the clusters as the dense region having some similarity and different from the lower dense region of the space. These methods have good accuracy and ability to merge two clusters.Example DBSCAN (Density-Based Spatial Clustering of Applications with Noise) , OPTICS (Ordering Points to Identify Clustering Structure) etc.\n","\n","2. Hierarchical Based Methods : The clusters formed in this method forms a tree type structure based on the hierarchy. New clusters are formed using the previously formed one. It is divided into two category\n","> * Agglomerative (bottom up approach)\n","> * Divisive (top down approach) .\n","examples CURE (Clustering Using Representatives), BIRCH (Balanced Iterative Reducing Clustering and using Hierarchies) etc.\n","\n","3. Partitioning Methods : These methods partition the objects into k clusters and each partition forms one cluster. This method is used to optimize an objective criterion similarity function such as when the distance is a major parameter example K-means, CLARANS (Clustering Large Applications based upon randomized Search) etc.\n","\n","4. Grid-based Methods : In this method the data space are formulated into a finite number of cells that form a grid-like structure. All the clustering operation done on these grids are fast and independent of the number of data objects example STING (Statistical Information Grid), wave cluster, CLIQUE (CLustering In Quest) etc.\n","\n","\n","Now if you would like some detailed notes on cluster analysis please take a look at these power point [slides](http://www.computing.dcu.ie/~amccarren/mcm_slides/Alternative_cluster_analysis_Presentation_2.ppt). I usually give these out as supplementary material in my lectures. They are very detailed and will take a bit of reading, but they are a good guide to determing which algorithm might suit your needs.\n","\n","In the next number of steps I will outline a number of metrics that are used to measure similarity and I will then then go through a number of clustering algorithms which will include K-mean,K-mediods and DBSCAN.  Finally, we will show you how to assess your clustering techniques with a comparison of the within cluster variation compared to the between cluster variation.    \n","\n","Read the notes and ask yourself how would you know if you have \"good clusters\". As usual put your thoughts on the comments board.\n","\n"]}]}