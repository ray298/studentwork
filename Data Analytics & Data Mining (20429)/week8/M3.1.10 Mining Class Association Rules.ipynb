{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M4.1.10 Mining Class Association Rules.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rndc7qKBpSxg","colab_type":"text"},"source":["#**Mining Class Association Rules**\n","\n","Normal association rule mining does not have any target, as it finds all possible rules that exist in data.  For example any item can appear as a consequent or a condition of a rule. However, in some applications, the user is interested in some targets. For example the user has a set of text documents from some known topics. He/she wants to find out what words are associated or correlated with each topic. \n","\n","</br>\n","\n","#Problem definition\n","\n",">Let $T$ be a transaction data set consisting of n transactions. \n",">Each transaction is also labeled with a class $y$. \n","\n","> Let I be the set of all items in T, Y be the set of all class labels and $I \\cap Y = \\emptyset $. \n","\n",">A class association rule (CAR) is an implication of the form \n","$X \\mapsto y$, where $X \\subseteq I$, and $y \\; \\epsilon \\; Y$. \n","\n",">The definitions of support and confidence are the same as those for normal association rules. \n","\n","\n","</br>\n","\n","#An example\n","\n","Lets look at a  text document data set. In it we have documents that have key words in them and each set of words is categorised with a label.\n","\n","becomes:\n","\n","\n","\n","> Document | Relevant Words | Category\n","> --- | --- | --- |\n",">  doc 1: |\tStudent, Teach, School |\t  Education\n",">  doc 2: |\tStudent, School \t\t   |  Education \t\n",">  doc 3: |\tTeach, School, City, Game |\t  Education\n","> doc 4: \t| Baseball, Basketball\t\t |   Sport\n","> doc 5: \t| Basketball, Player, Spectator  |\t  Sport\n","> doc 6: \t| Baseball, Coach, Game, Team | Sport\n","> doc 7: \t| Basketball, Team, City, Game \t | Sport\n","\n","In this example we want to examine the support and confidence for a group of words\n","\n",">Let $minsup = 20%\\ $ and $minconf = 60\\%$. \n","\n","</br>\n","\n","The following are two examples of class association rules:\n","\n",">$Student, School \\mapsto Education $\t$\\;\\;\\;[sup= 2/7, conf = 2/2]$\n","\n",">$game\\mapsto Sport$ $\\;\\;\\;  [sup= 2/7, conf = 2/3] $\n","\n","</br>\n","\n","Unlike normal association rules, CARs can be mined directly in one step. \n","\n","The key operation is to find all ruleitems that have support above minsup. A ruleitem is of the form: \n","\n","where condset is a set of items from I (i.e., $condset \\subseteq I$), and  $y \\;\\epsilon \\; Y$ is a class label. \n","\n","</br>\n","\n","Each ruleitem basically represents a rule:    \n","\n","?$condset \\mapsto y$,\n","\n","</br>\n","\n","The Apriori algorithm can be modified to generate CARs.The multiple minimum support idea can also be applied here. \n","The user can specify different minimum supports to different classes, which effectively assign a different minimum support to rules of each class. \n","For example, we have a data set with two classes, Yes and No. We may want \n","rules of class Yes to have the minimum support of 5% and \n","rules of class No to have the minimum support of 10%. \n","By setting minimum class supports to 100% (or more for some classes), we tell the algorithm not to generate rules of those classes. \n","This is a very useful trick in applications. \n","\n","Can you think of any other examples that we could use CARs for?\n","\n"]}]}