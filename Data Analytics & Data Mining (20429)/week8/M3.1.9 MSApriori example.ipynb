{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"iXI-2fY8LvX3"},"source":["#**MS-Apriori Example**\n","\n","The MS apriori example I am going to show you here was written by Bing Liu and is located on [Github](https://github.com/sachinbiradar9/MS-Apriori). Additionally, this code is not supported by Python 3.7 so you will have to set the runtime to Python 2 in the options above. Normally, I would use the Google drive id's to reference files, but in this situation I want to follow the instructions exactly,so I have mounted google drive as a virtual drive in the code snippet below. There are other versions of this online and you may find this [one](https://github.com/pavvu/FindFrequentItemSetWithMultipleItemSupport/blob/master/README.md) more useful.\n","\n","Now you will also have to download the [transaction.txt](https://drive.google.com/open?id=1h8OQVtB_hWtLa-FBtiRvzHfj4R61eMM4) and [parameter.txt](https://drive.google.com/open?id=1h7yURNdwcfqHrRnjK9TYwqjovJwTwr4d) files and store them on your google drive, or where ever you want to run them from."]},{"cell_type":"markdown","metadata":{"id":"8URjuZsVSUdG"},"source":["As you can see from the code above I have put my files on my google drive in a directory called \"/content/drive/My Drive/dcu/future Learn_v2/MOOC 4 - CA683 - Feature engineering/M2 Colab Files/Data\".\n","\n","The  transaction file is basically a list of all the transaction lists.\n","\n","The parameter file is a list of the possible MIS for each product, the SDC and some basic rules. The SDC is a limit that stops you putting extremely rare and a common item in the same itemset.  If the difference in support between the rare and common item is greater than this value then the itemset will be forbidden.\n","\n","Now the code by Bing is written below and reuires you to insert the name of your transaction file, your parameter file and your output file.\n","\n","Run the code and see how you get on."]},{"cell_type":"code","metadata":{"id":"KEykL73jIF2J","outputId":"4822eb30-ee61-47a8-be9b-d4656e800d8a","executionInfo":{"status":"ok","timestamp":1739974109428,"user_tz":0,"elapsed":285,"user":{"displayName":"Andrew Mccarren","userId":"16186536572019350587"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["import itertools\n","import re\n","from sys import argv\n","\n","\n","print( 'Computing frequent item sets.')\n","\n","transaction_file = '/content/sample_data/transaction.txt'\n","parameter_file = '/content/sample_data/parameter.txt'\n","output_file = '/content/sample_data/output.txt'\n","\n","\n","def fileParser(transaction_file, parameter_file):\n","    T = []\n","    with open(transaction_file,'r') as trans:\n","        for row in trans:\n","            transarr = re.findall(r'{.*?}',row)\n","            T.extend([map(str, list(eval(innerrow))) for innerrow in transarr])\n","\n","    with open(parameter_file,'r') as param:\n","        data = [row for row in param]\n","\n","    MS = {}\n","    cannot_be_together = []\n","    must_have = []\n","    for index, d in enumerate(data):\n","        if d[0] == 'M':\n","            match = re.match(r'^.*\\((.*)\\).*= (\\d*\\.\\d*)', d)\n","            MS[match.group(1)] = float(match.group(2))\n","        elif d[0] == 'S':\n","            max_sup_diff = float(re.match(r'.*= (.*)', d).group(1))\n","        elif d[0] == 'm':\n","            must_have = [x.strip() for x in d.split(':')[1].split('or')]\n","        elif d[0] == 'c':\n","            cannot_be_together = [map(str, list(eval(x))) for x in re.findall(r'{.*?}',d)]\n","\n","    return T, MS, max_sup_diff, cannot_be_together, must_have\n","\n","\n","def init_pass(M, T):\n","    L = []\n","    for t in T:\n","        for i in t:\n","            sup_count[i] = sup_count.get(i,0)+1\n","    smallest_sup = None\n","    for m in M:\n","        if smallest_sup:\n","            if m in sup_count and sup_count[m]/n >= smallest_sup:\n","                L.append(m)\n","        elif m in sup_count and sup_count[m]/n >= MS[m]:\n","            L.append(m)\n","            smallest_sup = MS[m]\n","    return L\n","\n","\n","def level2_candidate_gen(L):\n","    c = []\n","    for i,l in enumerate(L):\n","        if sup_count[l]/n >= MS[l]:\n","            for j in range (i+1,len(L)):\n","                if sup_count[L[j]]/n > MS[l] and abs(sup_count[L[j]]/n - sup_count[l]/n) <= max_sup_diff:\n","                    c.append({'c':[l, L[j]],'count':0})\n","    return c\n","\n","\n","def MScandidate_gen(F, k):\n","    c = []\n","    for index,f1 in enumerate(F):\n","        for j,f2 in enumerate(F[index+1:]):\n","            if set(f1[:-1]) == set(f2[:-1]) and abs(sup_count[f2[k-2]]/n - sup_count[f1[k-2]]/n) <= max_sup_diff:  #MS[f2[k-2]] > MS[f1[k-2]]) required?\n","                candidate = list(f1)\n","                candidate.append(f2[k-2])\n","                delete = False\n","                for s in list(itertools.combinations(candidate, k-1)):\n","                    if candidate[0] in s or MS[candidate[0]] == MS[candidate[1]]:\n","                        if list(s) not in F:\n","                            delete = True\n","                if not delete:\n","                    c.append({'c':candidate,'count':0})\n","    return c\n","\n","\n","def apply_constraints(F, must_have, cannot_be_together):\n","    F1 = {}\n","    for k in F:\n","        F1[k] = []\n","        for f in F[k]:\n","            delete = False\n","            if set(f).intersection(set(must_have)):\n","                for c in cannot_be_together:\n","                    if set(c).issubset(set(f)):\n","                        delete = True\n","                        break\n","                if not delete:\n","                    F1[k].append(f)\n","    return F1\n","\n","\n","def print_in_format(F):\n","    out_file = open(output_file, 'w')\n","    for k in F:\n","        out_file.write('Frequent ' + str(k) + '-itemsets\\n')\n","        for f in F[k]:\n","            if k == 1:\n","                out_file.write('\\n    ' + str(sup_count[f[0]]) + ' : {' + ','.join(set(f)) + '}')\n","            else:\n","                tail_count = 0\n","                for c in C[k]:\n","                    if set(c['c']) == set(f):\n","                        count = c['count']\n","                if k == 2:\n","                    tail_count = sup_count[f[k-1]]\n","                else:\n","                    for c in C[k-1]:\n","                        if set(c['c']) == set(f[1:]):\n","                            tail_count = c['count']\n","                out_file.write(\"\\n    \" + str(count) + \" : \" + '{' + ', '.join(f) + '}')\n","                out_file.write(\"\\nTailcount = \" + str(tail_count))\n","        out_file.write(\"\\n\\n    Total number of freuqent \"+ str(k) + \"-itemsets = \" + str(len(F[k])) + \"\\n\\n\\n\")\n","\n","\n","T, MS, max_sup_diff, cannot_be_together, must_have = fileParser(transaction_file, parameter_file)\n","n = float(len(T))\n","F = {}\n","sup_count = {}\n","C = {}\n","M = []\n","\n","for item,mis in sorted(MS.items(), key=lambda x: (x[1],int(x[0]))):\n","    M.append(item)\n","\n","L = init_pass(M, T)\n","if L:\n","    F[1] = [[L[0]]]\n","else:\n","    out_file = open(output_file, 'w')\n","    out_file.write(\"No frequent items found\")\n","    print( \"Please find output in \" + output_file)\n","    exit()\n","\n","for l in L[1:]:\n","    if sup_count[l]/n >= MS[l]:\n","        F[1].append([l])\n","\n","for k in range(2,15):\n","    if k == 2:\n","        C[k] = level2_candidate_gen(L)\n","    else:\n","        C[k] = MScandidate_gen(F[k-1],k)\n","\n","    for c in C[k]:\n","        sub_found = False\n","        sub_count = True\n","        if k > 2:\n","            for c1 in C[k-1]:\n","                if set(c['c'][1:]) == set(c1['c']):\n","                    sub_found == True\n","                    if c1['count'] != 0:\n","                        sub_count = False\n","            if sub_count and not sub_found:\n","                C[k-1].append({'c':c['c'][1:], 'count':0})\n","        for t in T:\n","            if set(c['c']).issubset(t):\n","                c['count']+=1\n","            if k > 2 and sub_count:\n","                if set(c['c'][1:]).issubset(t):\n","                    C[k-1][-1]['count'] +=1\n","    if not C[k]:\n","        break\n","\n","    F[k] = []\n","    for c in C[k]:\n","        if c['count']/n >= MS[c['c'][0]]:\n","            F[k].append(c['c'])\n","\n","    if len(F[k]) < 2:\n","        break\n","\n","\n","F1 = apply_constraints(F, must_have, cannot_be_together)\n","print_in_format(F1)\n","print (\"Please find output in \" + output_file)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Computing frequent item sets.\n","Please find output in /content/sample_data/output.txt\n"]}]},{"cell_type":"markdown","metadata":{"id":"6MNpCy9ER8WP"},"source":["The code above generates an output.txt file and this should go into your google drive, or where ever you directed the code snippet with the \"os.chdir\" command. Change the MIS for a number of products and see how you get on."]}]}