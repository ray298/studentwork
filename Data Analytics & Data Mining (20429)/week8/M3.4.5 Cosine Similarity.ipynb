{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"M4.4.5 Cosine Similarity.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMCHoSix3svrikYA1erNZrf"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"e_A-7zhB7qf0","colab_type":"text"},"source":["#**Cosine Similarity**\n","\n","Cosine similarity has been used to assess how similar documents are with each other. Where Euclidean distance measures the magnitude of the separation between 2 vectors, cosine similarity gives a measure of the angle between 2 multidimensional vectors. It is very similar to correlation where the [cosine similarity](https://brenocon.com/blog/2012/03/cosine-similarity-pearson-correlation-and-ols-coefficients/) between centered versions of x and y, again bounded between -1 and 1.\n","Cosine similarity is a metric used to measure how similar the documents are irrespective of their size. \n","\n","The maths behind this measure are derived from the Euclidean dot product:\n","\n","</br>\n","\n","<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/fb9fc371e46e02d0ef51e781e7397629425856b5\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.838ex; width:22.631ex; height:2.843ex;\" alt=\"{\\displaystyle \\mathbf {A} \\cdot \\mathbf {B} =\\left\\|\\mathbf {A} \\right\\|\\left\\|\\mathbf {B} \\right\\|\\cos \\theta }\">\n","\n","this can be converted to similarity by doing some simple algebra:\n","\n","<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1d94e5903f7936d3c131e040ef2c51b473dd071d\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -7.338ex; width:52.215ex; height:14.343ex;\" alt=\"{\\displaystyle {\\text{similarity}}=\\cos(\\theta )={\\mathbf {A} \\cdot \\mathbf {B}  \\over \\|\\mathbf {A} \\|\\|\\mathbf {B} \\|}={\\frac {\\sum \\limits _{i=1}^{n}{A_{i}B_{i}}}{{\\sqrt {\\sum \\limits _{i=1}^{n}{A_{i}^{2}}}}{\\sqrt {\\sum \\limits _{i=1}^{n}{B_{i}^{2}}}}}},}\">\n","\n","Cosine similarity is generally used when the magnitude of the vector does not matter. The term $\\vec{A}\\|\\cos{\\theta}$ tells where the projection vector $\\vec{A}$ lands on vector $\\vec{B}$, Figure 1\n","\n","![alt text](https://www.computing.dcu.ie/~amccarren/mcm_images/Dot_Product.png)\n","\n","Figure 1: the projection of $\\vec{A}$ on $\\vec{B}$, Wilipedia\n","\n","</br>\n","\n","The following code from Github implements Scikit learns cosine_similarity. You should notice how two vectors going in the same direction but with differing magnitudes have the same cosine similarity with $\\vec{X}$ and $\\vec{Y}$:\n","\n","$$\\vec{z} = [1~ 1~ 1~ 1]$$\n","\n","$$\\vec{z_2} = [100 ~ 100~ 100~ 100]$$\n","\n","but when we get the euclidean distance there is a vast difference.\n","\n","Again, play with these measures. Would you expect z and z2 to be correlated with each other? Place your thoughts on the comments board.\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"yylA0jwbHLoL","colab_type":"code","outputId":"7eb85aaa-875b-470a-9435-d4ff7891d0b3","executionInfo":{"status":"ok","timestamp":1580715121972,"user_tz":0,"elapsed":1826,"user":{"displayName":"Andrew McCarren","photoUrl":"","userId":"16186536572019350587"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# The usual creation of arrays produces wrong format (as cosine_similarity works on matrices)\n","x = np.array([2,3,1,0])\n","y = np.array([2,3,0,0])\n","\n","# Need to reshape these\n","x = x.reshape(1,-1)\n","y = y.reshape(1,-1)\n","\n","# Or just create as a single row matrix\n","z = np.array([[1,1,1,1]])\n","z2 = np.array([[100,100,100,100]])\n","\n","\n","# Now we can compute similarities\n","print(cosine_similarity(x,z)) \n","print(cosine_similarity(x,z2)) \n","print(cosine_similarity(y,z)) \n","print(cosine_similarity(y,z2)) \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.80178373]]\n","[[0.80178373]]\n","[[0.69337525]]\n","[[0.69337525]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SEhiZqt87grx","colab_type":"code","outputId":"aec8f4ae-6f5a-4098-c038-ef816fe42cc7","executionInfo":{"status":"ok","timestamp":1580715205160,"user_tz":0,"elapsed":1192,"user":{"displayName":"Andrew McCarren","photoUrl":"","userId":"16186536572019350587"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["from sklearn.metrics.pairwise import euclidean_distances\n","X = np.array([2,3,1,0])\n","X = x.reshape(1,-1)\n","z = np.array([[1,1,1,1]])\n","z2 = np.array([[100,100,100,100]])\n","# distance between rows of X\n","\n","print(euclidean_distances(X, z))\n","print(euclidean_distances(X, z2))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[2.44948974]]\n","[[197.01268995]]\n"],"name":"stdout"}]}]}